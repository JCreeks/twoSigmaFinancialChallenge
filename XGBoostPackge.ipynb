{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import log_loss, mean_squared_error as mse, r2_score \n",
    "from sklearn.metrics.scorer import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def runXGB(X_train, y_train, X_test=None, num_class=1, feature_names=None, seed=0, num_rounds=1000, early_stopping_rounds=None):\n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:linear', #'multi:softprob'\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 1, #0.85, #like max_features\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'seed': seed,\n",
    "    'silent': 0,\n",
    "    'eval_metric': 'rmse' # \"logloss\", \"mlogloss\", auc\" # for ranking \n",
    "    }\n",
    "    \n",
    "    if num_class!=1:\n",
    "        params['num_class']=num_class\n",
    "\n",
    "    plst = list(params.items())\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    \n",
    "    model = xgb.train(plst, dtrain, num_boost_round=num_rounds, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "    if X_test is not None:\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        pred = model.predict(dtest)\n",
    "        return pred, model\n",
    "    return None, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def runXGBShuffle(X_train, y_train, X_test, num_class=1, feature_names=None, seed=0, num_rounds=1000, test_size=.3, \\\n",
    "               early_stopping_rounds=None):\n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:linear', #'multi:softprob'\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 1, #0.85, #like max_features\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'seed': seed,\n",
    "    'silent': 0,\n",
    "    'eval_metric': 'rmse' # \"logloss\", \"mlogloss\", auc\" # for ranking \n",
    "    }\n",
    "    \n",
    "    if num_class!=1:\n",
    "        params['num_class']=num_class\n",
    "\n",
    "    plst = list(params.items())\n",
    "    X_dtrain, X_deval, y_dtrain, y_deval=train_test_split(X_train, y_train, random_state=seed, test_size=test_size)\n",
    "    dtrain = xgb.DMatrix(X_dtrain, y_dtrain)\n",
    "    deval = xgb.DMatrix(X_deval, y_deval)\n",
    "    watchlist = [(deval, 'eval')]\n",
    "    \n",
    "    model = xgb.train(plst, dtrain, num_rounds, watchlist, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "    if X_test is not None:\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        pred = model.predict(dtest)\n",
    "        return pred, model\n",
    "    return None, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class xgbClass(object):\n",
    "    def __init__(self, eta=.1, subsample=.8, num_class=1, max_depth=5, seed=17, silent=0, eva_metric='mlogloss',\\\n",
    "                colsample_bytree=1, objective='solfprob'):\n",
    "        self.params={\n",
    "        'objective' : objective, #'reg:linear','multi:softprob'\n",
    "        'subsample' : subsample,\n",
    "        'colsample_bytree' : colsample_bytree, #like max_features\n",
    "        'eta': eta,\n",
    "        'max_depth': max_depth,\n",
    "        'seed': seed,\n",
    "        'silent': silent,\n",
    "        'eval_metric': eva_metric#'rmse' \"logloss\", \"mlogloss\", auc\" # for ranking \n",
    "        }\n",
    "        \n",
    "        if num_class!=1:\n",
    "            self.params['num_class']=num_class\n",
    "        self.model=[]\n",
    "        \n",
    "    def fit(self, X_train, y_train, num_rounds=500, early_stopping_rounds=None):\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        self.model = xgb.train(self.params, dtrain, num_boost_round=num_rounds, early_stopping_rounds=early_stopping_rounds)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        return self.model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n=100000\n",
    "X=pd.DataFrame(np.random.randn(n,1))\n",
    "y=X.iloc[:,0]+.2*pd.Series(np.random.randn(n))\n",
    "X_train,y_train=X.iloc[:n/2], y.iloc[:n/2]\n",
    "X_test, y_test=X.iloc[n/2:], y.iloc[n/2:]\n",
    "\n",
    "# import kagglegym\n",
    "# env = kagglegym.make()\n",
    "# o = env.reset()\n",
    "# excl = [env.ID_COL_NAME, env.SAMPLE_COL_NAME, env.TARGET_COL_NAME, env.TIME_COL_NAME]\n",
    "# col = [c for c in o.train.columns if c not in excl]\n",
    "\n",
    "# O = pd.read_hdf('../input/train.h5')\n",
    "# d_mean= O[col].median(axis=0)\n",
    "\n",
    "# ymean_dict = dict(o.train.groupby([\"id\"])[\"y\"].median())\n",
    "\n",
    "# X_train=(O[col])[O.timestamp <= 905]\n",
    "# y_train=O.y[O.timestamp <= 905]\n",
    "# X_test=(O[col])[O.timestamp > 905]\n",
    "# y_test=O.y[O.timestamp > 905]\n",
    "# X_train=X_train.fillna(d_mean)\n",
    "# X_test=X_test.fillna(d_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95912476935\n"
     ]
    }
   ],
   "source": [
    "pred, model=runXGB(X_train=X_train, y_train=y_train, X_test=X_test, num_rounds=500)\n",
    "print(r2_score(pred, y_test))\n",
    "#-44.5409187933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:1.08444\n",
      "[1]\teval-rmse:1.03227\n",
      "[2]\teval-rmse:0.982866\n",
      "[3]\teval-rmse:0.93602\n",
      "[4]\teval-rmse:0.891542\n",
      "[5]\teval-rmse:0.849469\n",
      "[6]\teval-rmse:0.809562\n",
      "[7]\teval-rmse:0.771749\n",
      "[8]\teval-rmse:0.735948\n",
      "[9]\teval-rmse:0.702123\n",
      "[10]\teval-rmse:0.670081\n",
      "[11]\teval-rmse:0.639809\n",
      "[12]\teval-rmse:0.611173\n",
      "[13]\teval-rmse:0.584058\n",
      "[14]\teval-rmse:0.558446\n",
      "[15]\teval-rmse:0.534348\n",
      "[16]\teval-rmse:0.511632\n",
      "[17]\teval-rmse:0.490155\n",
      "[18]\teval-rmse:0.469953\n",
      "[19]\teval-rmse:0.45091\n",
      "[20]\teval-rmse:0.433076\n",
      "[21]\teval-rmse:0.416246\n",
      "[22]\teval-rmse:0.400447\n",
      "[23]\teval-rmse:0.3856\n",
      "[24]\teval-rmse:0.371737\n",
      "[25]\teval-rmse:0.358743\n",
      "[26]\teval-rmse:0.346619\n",
      "[27]\teval-rmse:0.335264\n",
      "[28]\teval-rmse:0.324691\n",
      "[29]\teval-rmse:0.314848\n",
      "[30]\teval-rmse:0.305699\n",
      "[31]\teval-rmse:0.297187\n",
      "[32]\teval-rmse:0.289293\n",
      "[33]\teval-rmse:0.281913\n",
      "[34]\teval-rmse:0.275099\n",
      "[35]\teval-rmse:0.268825\n",
      "[36]\teval-rmse:0.263026\n",
      "[37]\teval-rmse:0.257696\n",
      "[38]\teval-rmse:0.252784\n",
      "[39]\teval-rmse:0.248266\n",
      "[40]\teval-rmse:0.244088\n",
      "[41]\teval-rmse:0.240266\n",
      "[42]\teval-rmse:0.236781\n",
      "[43]\teval-rmse:0.233602\n",
      "[44]\teval-rmse:0.2307\n",
      "[45]\teval-rmse:0.228006\n",
      "[46]\teval-rmse:0.225546\n",
      "[47]\teval-rmse:0.223311\n",
      "[48]\teval-rmse:0.221309\n",
      "[49]\teval-rmse:0.219458\n",
      "[50]\teval-rmse:0.217782\n",
      "[51]\teval-rmse:0.21626\n",
      "[52]\teval-rmse:0.214858\n",
      "[53]\teval-rmse:0.213579\n",
      "[54]\teval-rmse:0.212427\n",
      "[55]\teval-rmse:0.211376\n",
      "[56]\teval-rmse:0.210447\n",
      "[57]\teval-rmse:0.209589\n",
      "[58]\teval-rmse:0.208824\n",
      "[59]\teval-rmse:0.208107\n",
      "[60]\teval-rmse:0.20746\n",
      "[61]\teval-rmse:0.206885\n",
      "[62]\teval-rmse:0.206359\n",
      "[63]\teval-rmse:0.205863\n",
      "[64]\teval-rmse:0.205439\n",
      "[65]\teval-rmse:0.205053\n",
      "[66]\teval-rmse:0.204696\n",
      "[67]\teval-rmse:0.204374\n",
      "[68]\teval-rmse:0.204092\n",
      "[69]\teval-rmse:0.20384\n",
      "[70]\teval-rmse:0.203616\n",
      "[71]\teval-rmse:0.203417\n",
      "[72]\teval-rmse:0.203233\n",
      "[73]\teval-rmse:0.203063\n",
      "[74]\teval-rmse:0.202908\n",
      "[75]\teval-rmse:0.202767\n",
      "[76]\teval-rmse:0.20263\n",
      "[77]\teval-rmse:0.202518\n",
      "[78]\teval-rmse:0.202406\n",
      "[79]\teval-rmse:0.202312\n",
      "[80]\teval-rmse:0.202226\n",
      "[81]\teval-rmse:0.202161\n",
      "[82]\teval-rmse:0.202101\n",
      "[83]\teval-rmse:0.202031\n",
      "[84]\teval-rmse:0.201967\n",
      "[85]\teval-rmse:0.201923\n",
      "[86]\teval-rmse:0.20188\n",
      "[87]\teval-rmse:0.201838\n",
      "[88]\teval-rmse:0.201795\n",
      "[89]\teval-rmse:0.201771\n",
      "[90]\teval-rmse:0.201753\n",
      "[91]\teval-rmse:0.201721\n",
      "[92]\teval-rmse:0.201691\n",
      "[93]\teval-rmse:0.201669\n",
      "[94]\teval-rmse:0.201654\n",
      "[95]\teval-rmse:0.201642\n",
      "[96]\teval-rmse:0.201625\n",
      "[97]\teval-rmse:0.201606\n",
      "[98]\teval-rmse:0.201594\n",
      "[99]\teval-rmse:0.201584\n",
      "[100]\teval-rmse:0.20157\n",
      "[101]\teval-rmse:0.201564\n",
      "[102]\teval-rmse:0.201561\n",
      "[103]\teval-rmse:0.201556\n",
      "[104]\teval-rmse:0.20155\n",
      "[105]\teval-rmse:0.201541\n",
      "[106]\teval-rmse:0.201536\n",
      "[107]\teval-rmse:0.201529\n",
      "[108]\teval-rmse:0.201524\n",
      "[109]\teval-rmse:0.201519\n",
      "[110]\teval-rmse:0.201519\n",
      "[111]\teval-rmse:0.201513\n",
      "[112]\teval-rmse:0.20151\n",
      "[113]\teval-rmse:0.201511\n",
      "[114]\teval-rmse:0.20151\n",
      "[115]\teval-rmse:0.201519\n",
      "[116]\teval-rmse:0.201524\n",
      "[117]\teval-rmse:0.201516\n",
      "[118]\teval-rmse:0.201515\n",
      "[119]\teval-rmse:0.201522\n",
      "[120]\teval-rmse:0.201523\n",
      "[121]\teval-rmse:0.20153\n",
      "[122]\teval-rmse:0.201524\n",
      "[123]\teval-rmse:0.201526\n",
      "[124]\teval-rmse:0.201532\n",
      "[125]\teval-rmse:0.201533\n",
      "[126]\teval-rmse:0.201531\n",
      "[127]\teval-rmse:0.201532\n",
      "[128]\teval-rmse:0.201532\n",
      "[129]\teval-rmse:0.201537\n",
      "[130]\teval-rmse:0.201538\n",
      "[131]\teval-rmse:0.201541\n",
      "[132]\teval-rmse:0.201542\n",
      "[133]\teval-rmse:0.201543\n",
      "[134]\teval-rmse:0.201546\n",
      "[135]\teval-rmse:0.20155\n",
      "[136]\teval-rmse:0.201546\n",
      "[137]\teval-rmse:0.201556\n",
      "[138]\teval-rmse:0.201559\n",
      "[139]\teval-rmse:0.201566\n",
      "[140]\teval-rmse:0.20157\n",
      "[141]\teval-rmse:0.201577\n",
      "[142]\teval-rmse:0.201582\n",
      "[143]\teval-rmse:0.201579\n",
      "[144]\teval-rmse:0.201582\n",
      "[145]\teval-rmse:0.201586\n",
      "[146]\teval-rmse:0.201587\n",
      "[147]\teval-rmse:0.201591\n",
      "[148]\teval-rmse:0.201602\n",
      "[149]\teval-rmse:0.201602\n",
      "[150]\teval-rmse:0.201606\n",
      "[151]\teval-rmse:0.201605\n",
      "[152]\teval-rmse:0.201612\n",
      "[153]\teval-rmse:0.201617\n",
      "[154]\teval-rmse:0.201616\n",
      "[155]\teval-rmse:0.201619\n",
      "[156]\teval-rmse:0.201618\n",
      "[157]\teval-rmse:0.201618\n",
      "[158]\teval-rmse:0.201625\n",
      "[159]\teval-rmse:0.201625\n",
      "[160]\teval-rmse:0.201633\n",
      "[161]\teval-rmse:0.201626\n",
      "[162]\teval-rmse:0.201636\n",
      "[163]\teval-rmse:0.201637\n",
      "[164]\teval-rmse:0.201641\n",
      "[165]\teval-rmse:0.20165\n",
      "[166]\teval-rmse:0.201652\n",
      "[167]\teval-rmse:0.201652\n",
      "[168]\teval-rmse:0.201663\n",
      "[169]\teval-rmse:0.201664\n",
      "[170]\teval-rmse:0.201662\n",
      "[171]\teval-rmse:0.201665\n",
      "[172]\teval-rmse:0.201665\n",
      "[173]\teval-rmse:0.20166\n",
      "[174]\teval-rmse:0.201665\n",
      "[175]\teval-rmse:0.201671\n",
      "[176]\teval-rmse:0.201679\n",
      "[177]\teval-rmse:0.201683\n",
      "[178]\teval-rmse:0.201693\n",
      "[179]\teval-rmse:0.201699\n",
      "[180]\teval-rmse:0.201699\n",
      "[181]\teval-rmse:0.201694\n",
      "[182]\teval-rmse:0.201701\n",
      "[183]\teval-rmse:0.201703\n",
      "[184]\teval-rmse:0.201711\n",
      "[185]\teval-rmse:0.201717\n",
      "[186]\teval-rmse:0.201722\n",
      "[187]\teval-rmse:0.201725\n",
      "[188]\teval-rmse:0.201728\n",
      "[189]\teval-rmse:0.201738\n",
      "[190]\teval-rmse:0.201747\n",
      "[191]\teval-rmse:0.201745\n",
      "[192]\teval-rmse:0.201744\n",
      "[193]\teval-rmse:0.201739\n",
      "[194]\teval-rmse:0.201737\n",
      "[195]\teval-rmse:0.201735\n",
      "[196]\teval-rmse:0.201739\n",
      "[197]\teval-rmse:0.201741\n",
      "[198]\teval-rmse:0.201742\n",
      "[199]\teval-rmse:0.201751\n",
      "[200]\teval-rmse:0.201752\n",
      "[201]\teval-rmse:0.20175\n",
      "[202]\teval-rmse:0.201756\n",
      "[203]\teval-rmse:0.201754\n",
      "[204]\teval-rmse:0.201762\n",
      "[205]\teval-rmse:0.201763\n",
      "[206]\teval-rmse:0.201765\n",
      "[207]\teval-rmse:0.201771\n",
      "[208]\teval-rmse:0.201782\n",
      "[209]\teval-rmse:0.20178\n",
      "[210]\teval-rmse:0.201777\n",
      "[211]\teval-rmse:0.201782\n",
      "[212]\teval-rmse:0.201785\n",
      "[213]\teval-rmse:0.201787\n",
      "[214]\teval-rmse:0.201783\n",
      "[215]\teval-rmse:0.20178\n",
      "[216]\teval-rmse:0.201782\n",
      "[217]\teval-rmse:0.201787\n",
      "[218]\teval-rmse:0.201796\n",
      "[219]\teval-rmse:0.201798\n",
      "[220]\teval-rmse:0.201795\n",
      "[221]\teval-rmse:0.201792\n",
      "[222]\teval-rmse:0.201794\n",
      "[223]\teval-rmse:0.20179\n",
      "[224]\teval-rmse:0.201789\n",
      "[225]\teval-rmse:0.201785\n",
      "[226]\teval-rmse:0.201789\n",
      "[227]\teval-rmse:0.201786\n",
      "[228]\teval-rmse:0.20179\n",
      "[229]\teval-rmse:0.201791\n",
      "[230]\teval-rmse:0.201797\n",
      "[231]\teval-rmse:0.201798\n",
      "[232]\teval-rmse:0.201798\n",
      "[233]\teval-rmse:0.201797\n",
      "[234]\teval-rmse:0.201797\n",
      "[235]\teval-rmse:0.2018\n",
      "[236]\teval-rmse:0.2018\n",
      "[237]\teval-rmse:0.201809\n",
      "[238]\teval-rmse:0.201815\n",
      "[239]\teval-rmse:0.201818\n",
      "[240]\teval-rmse:0.201823\n",
      "[241]\teval-rmse:0.201826\n",
      "[242]\teval-rmse:0.201826\n",
      "[243]\teval-rmse:0.201829\n",
      "[244]\teval-rmse:0.201832\n",
      "[245]\teval-rmse:0.20183\n",
      "[246]\teval-rmse:0.201844\n",
      "[247]\teval-rmse:0.20185\n",
      "[248]\teval-rmse:0.201854\n",
      "[249]\teval-rmse:0.201858\n",
      "[250]\teval-rmse:0.20186\n",
      "[251]\teval-rmse:0.201857\n",
      "[252]\teval-rmse:0.20186\n",
      "[253]\teval-rmse:0.20186\n",
      "[254]\teval-rmse:0.201862\n",
      "[255]\teval-rmse:0.201867\n",
      "[256]\teval-rmse:0.201869\n",
      "[257]\teval-rmse:0.201876\n",
      "[258]\teval-rmse:0.201876\n",
      "[259]\teval-rmse:0.201878\n",
      "[260]\teval-rmse:0.201882\n",
      "[261]\teval-rmse:0.20188\n",
      "[262]\teval-rmse:0.201888\n",
      "[263]\teval-rmse:0.201885\n",
      "[264]\teval-rmse:0.201889\n",
      "[265]\teval-rmse:0.201888\n",
      "[266]\teval-rmse:0.201892\n",
      "[267]\teval-rmse:0.201891\n",
      "[268]\teval-rmse:0.201895\n",
      "[269]\teval-rmse:0.201896\n",
      "[270]\teval-rmse:0.201902\n",
      "[271]\teval-rmse:0.201905\n",
      "[272]\teval-rmse:0.201905\n",
      "[273]\teval-rmse:0.201908\n",
      "[274]\teval-rmse:0.201911\n",
      "[275]\teval-rmse:0.201916\n",
      "[276]\teval-rmse:0.201928\n",
      "[277]\teval-rmse:0.201924\n",
      "[278]\teval-rmse:0.201938\n",
      "[279]\teval-rmse:0.201944\n",
      "[280]\teval-rmse:0.201947\n",
      "[281]\teval-rmse:0.201943\n",
      "[282]\teval-rmse:0.201938\n",
      "[283]\teval-rmse:0.201931\n",
      "[284]\teval-rmse:0.20193\n",
      "[285]\teval-rmse:0.201927\n",
      "[286]\teval-rmse:0.201929\n",
      "[287]\teval-rmse:0.201938\n",
      "[288]\teval-rmse:0.201945\n",
      "[289]\teval-rmse:0.201943\n",
      "[290]\teval-rmse:0.201947\n",
      "[291]\teval-rmse:0.201948\n",
      "[292]\teval-rmse:0.20195\n",
      "[293]\teval-rmse:0.201951\n",
      "[294]\teval-rmse:0.201952\n",
      "[295]\teval-rmse:0.201954\n",
      "[296]\teval-rmse:0.201955\n",
      "[297]\teval-rmse:0.201955\n",
      "[298]\teval-rmse:0.201957\n",
      "[299]\teval-rmse:0.201963\n",
      "[300]\teval-rmse:0.201963\n",
      "[301]\teval-rmse:0.201969\n",
      "[302]\teval-rmse:0.201975\n",
      "[303]\teval-rmse:0.201976\n",
      "[304]\teval-rmse:0.201982\n",
      "[305]\teval-rmse:0.201987\n",
      "[306]\teval-rmse:0.201995\n",
      "[307]\teval-rmse:0.201996\n",
      "[308]\teval-rmse:0.201997\n",
      "[309]\teval-rmse:0.201999\n",
      "[310]\teval-rmse:0.201998\n",
      "[311]\teval-rmse:0.20199\n",
      "[312]\teval-rmse:0.201991\n",
      "[313]\teval-rmse:0.201989\n",
      "[314]\teval-rmse:0.201987\n",
      "[315]\teval-rmse:0.201988\n",
      "[316]\teval-rmse:0.201995\n",
      "[317]\teval-rmse:0.202002\n",
      "[318]\teval-rmse:0.202008\n",
      "[319]\teval-rmse:0.20201\n",
      "[320]\teval-rmse:0.202007\n",
      "[321]\teval-rmse:0.202008\n",
      "[322]\teval-rmse:0.202019\n",
      "[323]\teval-rmse:0.202021\n",
      "[324]\teval-rmse:0.202027\n",
      "[325]\teval-rmse:0.20203\n",
      "[326]\teval-rmse:0.202033\n",
      "[327]\teval-rmse:0.202032\n",
      "[328]\teval-rmse:0.202032\n",
      "[329]\teval-rmse:0.202037\n",
      "[330]\teval-rmse:0.202044\n",
      "[331]\teval-rmse:0.202043\n",
      "[332]\teval-rmse:0.202044\n",
      "[333]\teval-rmse:0.202044\n",
      "[334]\teval-rmse:0.202045\n",
      "[335]\teval-rmse:0.202046\n",
      "[336]\teval-rmse:0.202043\n",
      "[337]\teval-rmse:0.202047\n",
      "[338]\teval-rmse:0.202053\n",
      "[339]\teval-rmse:0.202054\n",
      "[340]\teval-rmse:0.202056\n",
      "[341]\teval-rmse:0.202058\n",
      "[342]\teval-rmse:0.202061\n",
      "[343]\teval-rmse:0.202067\n",
      "[344]\teval-rmse:0.202067\n",
      "[345]\teval-rmse:0.202072\n",
      "[346]\teval-rmse:0.202082\n",
      "[347]\teval-rmse:0.202081\n",
      "[348]\teval-rmse:0.202086\n",
      "[349]\teval-rmse:0.202094\n",
      "[350]\teval-rmse:0.202098\n",
      "[351]\teval-rmse:0.202101\n",
      "[352]\teval-rmse:0.202108\n",
      "[353]\teval-rmse:0.202114\n",
      "[354]\teval-rmse:0.202121\n",
      "[355]\teval-rmse:0.202126\n",
      "[356]\teval-rmse:0.202122\n",
      "[357]\teval-rmse:0.202126\n",
      "[358]\teval-rmse:0.20213\n",
      "[359]\teval-rmse:0.202133\n",
      "[360]\teval-rmse:0.202129\n",
      "[361]\teval-rmse:0.202128\n",
      "[362]\teval-rmse:0.202126\n",
      "[363]\teval-rmse:0.202131\n",
      "[364]\teval-rmse:0.202134\n",
      "[365]\teval-rmse:0.202131\n",
      "[366]\teval-rmse:0.202141\n",
      "[367]\teval-rmse:0.202144\n",
      "[368]\teval-rmse:0.202147\n",
      "[369]\teval-rmse:0.202146\n",
      "[370]\teval-rmse:0.20215\n",
      "[371]\teval-rmse:0.20215\n",
      "[372]\teval-rmse:0.202148\n",
      "[373]\teval-rmse:0.202152\n",
      "[374]\teval-rmse:0.202158\n",
      "[375]\teval-rmse:0.202167\n",
      "[376]\teval-rmse:0.202169\n",
      "[377]\teval-rmse:0.202164\n",
      "[378]\teval-rmse:0.202168\n",
      "[379]\teval-rmse:0.20217\n",
      "[380]\teval-rmse:0.202178\n",
      "[381]\teval-rmse:0.202178\n",
      "[382]\teval-rmse:0.202183\n",
      "[383]\teval-rmse:0.202183\n",
      "[384]\teval-rmse:0.202185\n",
      "[385]\teval-rmse:0.20219\n",
      "[386]\teval-rmse:0.202195\n",
      "[387]\teval-rmse:0.202201\n",
      "[388]\teval-rmse:0.2022\n",
      "[389]\teval-rmse:0.202201\n",
      "[390]\teval-rmse:0.202202\n",
      "[391]\teval-rmse:0.202211\n",
      "[392]\teval-rmse:0.202212\n",
      "[393]\teval-rmse:0.20221\n",
      "[394]\teval-rmse:0.202215\n",
      "[395]\teval-rmse:0.202221\n",
      "[396]\teval-rmse:0.202224\n",
      "[397]\teval-rmse:0.202235\n",
      "[398]\teval-rmse:0.202238\n",
      "[399]\teval-rmse:0.202239\n",
      "[400]\teval-rmse:0.202239\n",
      "[401]\teval-rmse:0.202241\n",
      "[402]\teval-rmse:0.202251\n",
      "[403]\teval-rmse:0.202254\n",
      "[404]\teval-rmse:0.202262\n",
      "[405]\teval-rmse:0.202264\n",
      "[406]\teval-rmse:0.202268\n",
      "[407]\teval-rmse:0.20226\n",
      "[408]\teval-rmse:0.202264\n",
      "[409]\teval-rmse:0.202262\n",
      "[410]\teval-rmse:0.202256\n",
      "[411]\teval-rmse:0.202265\n",
      "[412]\teval-rmse:0.20227\n",
      "[413]\teval-rmse:0.202272\n",
      "[414]\teval-rmse:0.202275\n",
      "[415]\teval-rmse:0.20228\n",
      "[416]\teval-rmse:0.202282\n",
      "[417]\teval-rmse:0.202284\n",
      "[418]\teval-rmse:0.202293\n",
      "[419]\teval-rmse:0.202298\n",
      "[420]\teval-rmse:0.202305\n",
      "[421]\teval-rmse:0.202297\n",
      "[422]\teval-rmse:0.202303\n",
      "[423]\teval-rmse:0.202305\n",
      "[424]\teval-rmse:0.202303\n",
      "[425]\teval-rmse:0.202305\n",
      "[426]\teval-rmse:0.202307\n",
      "[427]\teval-rmse:0.202309\n",
      "[428]\teval-rmse:0.202312\n",
      "[429]\teval-rmse:0.202312\n",
      "[430]\teval-rmse:0.202316\n",
      "[431]\teval-rmse:0.202318\n",
      "[432]\teval-rmse:0.202321\n",
      "[433]\teval-rmse:0.202324\n",
      "[434]\teval-rmse:0.202321\n",
      "[435]\teval-rmse:0.202324\n",
      "[436]\teval-rmse:0.202327\n",
      "[437]\teval-rmse:0.202331\n",
      "[438]\teval-rmse:0.202336\n",
      "[439]\teval-rmse:0.202345\n",
      "[440]\teval-rmse:0.202355\n",
      "[441]\teval-rmse:0.202356\n",
      "[442]\teval-rmse:0.202359\n",
      "[443]\teval-rmse:0.202368\n",
      "[444]\teval-rmse:0.202375\n",
      "[445]\teval-rmse:0.202379\n",
      "[446]\teval-rmse:0.202381\n",
      "[447]\teval-rmse:0.202383\n",
      "[448]\teval-rmse:0.202387\n",
      "[449]\teval-rmse:0.202392\n",
      "[450]\teval-rmse:0.202395\n",
      "[451]\teval-rmse:0.202392\n",
      "[452]\teval-rmse:0.202398\n",
      "[453]\teval-rmse:0.202399\n",
      "[454]\teval-rmse:0.202403\n",
      "[455]\teval-rmse:0.202403\n",
      "[456]\teval-rmse:0.202404\n",
      "[457]\teval-rmse:0.202406\n",
      "[458]\teval-rmse:0.202409\n",
      "[459]\teval-rmse:0.202415\n",
      "[460]\teval-rmse:0.202422\n",
      "[461]\teval-rmse:0.202427\n",
      "[462]\teval-rmse:0.202432\n",
      "[463]\teval-rmse:0.202429\n",
      "[464]\teval-rmse:0.202434\n",
      "[465]\teval-rmse:0.202435\n",
      "[466]\teval-rmse:0.202443\n",
      "[467]\teval-rmse:0.202448\n",
      "[468]\teval-rmse:0.202453\n",
      "[469]\teval-rmse:0.202453\n",
      "[470]\teval-rmse:0.202456\n",
      "[471]\teval-rmse:0.202456\n",
      "[472]\teval-rmse:0.202462\n",
      "[473]\teval-rmse:0.202455\n",
      "[474]\teval-rmse:0.202455\n",
      "[475]\teval-rmse:0.202465\n",
      "[476]\teval-rmse:0.202467\n",
      "[477]\teval-rmse:0.202461\n",
      "[478]\teval-rmse:0.202464\n",
      "[479]\teval-rmse:0.20247\n",
      "[480]\teval-rmse:0.202467\n",
      "[481]\teval-rmse:0.202466\n",
      "[482]\teval-rmse:0.202467\n",
      "[483]\teval-rmse:0.202467\n",
      "[484]\teval-rmse:0.20246\n",
      "[485]\teval-rmse:0.202467\n",
      "[486]\teval-rmse:0.202469\n",
      "[487]\teval-rmse:0.202471\n",
      "[488]\teval-rmse:0.202472\n",
      "[489]\teval-rmse:0.202471\n",
      "[490]\teval-rmse:0.202472\n",
      "[491]\teval-rmse:0.202477\n",
      "[492]\teval-rmse:0.202481\n",
      "[493]\teval-rmse:0.202485\n",
      "[494]\teval-rmse:0.202488\n",
      "[495]\teval-rmse:0.202487\n",
      "[496]\teval-rmse:0.202489\n",
      "[497]\teval-rmse:0.202494\n",
      "[498]\teval-rmse:0.202501\n",
      "[499]\teval-rmse:0.202507\n",
      "0.959105226137\n"
     ]
    }
   ],
   "source": [
    "pred, model=runXGBShuffle(X_train=X_train, y_train=y_train, X_test=X_test, num_rounds=500, test_size=.3)\n",
    "print(r2_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959140452508\n"
     ]
    }
   ],
   "source": [
    "model=xgbClass(objective='reg:linear', eva_metric='rmse')\n",
    "model.fit(X_train, y_train)\n",
    "pred=model.predict(X_test)\n",
    "print(r2_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
