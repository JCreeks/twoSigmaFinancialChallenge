{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806298, 111)\n",
      "(805548, 126)\n"
     ]
    }
   ],
   "source": [
    "import kagglegym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import ensemble, linear_model, metrics\n",
    "\n",
    "env = kagglegym.make()\n",
    "o = env.reset()\n",
    "train = o.train\n",
    "print(train.shape)\n",
    "d_mean= train.median(axis=0)\n",
    "train[\"nbnulls\"]=train.isnull().sum(axis=1)\n",
    "col=[x for x in train.columns if x not in ['id', 'timestamp', 'y']]\n",
    "\n",
    "rnd=17\n",
    "\n",
    "#keeping na information on some columns (best selected by the tree algorithms)\n",
    "add_nas_ft=True\n",
    "nas_cols=['technical_9', 'technical_0', 'technical_32', 'technical_16', 'technical_38', \n",
    "'technical_44', 'technical_20', 'technical_30', 'technical_13']\n",
    "#columns kept for evolution from one month to another (best selected by the tree algorithms)\n",
    "add_diff_ft=True\n",
    "diff_cols=['technical_22','technical_20', 'technical_30', 'technical_13', 'technical_34']\n",
    "\n",
    "if add_nas_ft:\n",
    "    for elt in nas_cols:\n",
    "        train[elt + '_na'] = pd.isnull(train[elt]).apply(lambda x: 1 if x else 0)\n",
    "        #no need to keep columns with no information\n",
    "        if len(train[elt + '_na'].unique())==1:\n",
    "            print(\"removed:\", elt, '_na')\n",
    "            del train[elt + '_na']\n",
    "            nas_cols.remove(elt)\n",
    "\n",
    "\n",
    "if add_diff_ft:\n",
    "    train=train.sort_values(by=['id','timestamp'])\n",
    "    for elt in diff_cols:\n",
    "        #a quick way to obtain deltas from one month to another but it is false on the first\n",
    "        #month of each id\n",
    "        train[elt+\"_d\"]= train[elt].rolling(2).apply(lambda x:x[1]-x[0]).fillna(0)\n",
    "    #removing month 0 to reduce the impact of erroneous deltas\n",
    "    train=train[train.timestamp!=0]\n",
    "\n",
    "print(train.shape)\n",
    "cols=[x for x in train.columns if x not in ['id', 'timestamp', 'y']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#homemade class used to infer randomly on the way the model learns\n",
    "class createLinearFeatures:\n",
    "    \n",
    "    def __init__(self, n_neighbours=1, max_elts=None, verbose=True, random_state=None):\n",
    "        self.rnd=random_state\n",
    "        self.n=n_neighbours\n",
    "        self.max_elts=max_elts\n",
    "        self.verbose=verbose\n",
    "        self.neighbours=[]\n",
    "        self.clfs=[]\n",
    "        \n",
    "    def fit(self,train,y):\n",
    "        if self.rnd!=None:\n",
    "            random.seed(self.rnd)\n",
    "        if self.max_elts==None:\n",
    "            self.max_elts=len(train.columns)\n",
    "        list_vars=list(train.columns)\n",
    "        random.shuffle(list_vars)\n",
    "        \n",
    "        lastscores=np.zeros(self.n)+1e15\n",
    "\n",
    "        for elt in list_vars[:self.n]:\n",
    "            self.neighbours.append([elt])\n",
    "        list_vars=list_vars[self.n:]\n",
    "        \n",
    "        for elt in list_vars:\n",
    "            indice=0\n",
    "            scores=[]\n",
    "            for elt2 in self.neighbours:\n",
    "                if len(elt2)<self.max_elts:\n",
    "                    clf=linear_model.LinearRegression(fit_intercept=False, normalize=True, copy_X=True, n_jobs=-1) \n",
    "                    clf.fit(train[elt2+[elt]], y)\n",
    "                    scores.append(metrics.mean_squared_error(y,clf.predict(train[elt2 + [elt]])))\n",
    "                    indice=indice+1\n",
    "                else:\n",
    "                    scores.append(lastscores[indice])\n",
    "                    indice=indice+1\n",
    "            gains=lastscores-scores\n",
    "            if gains.max()>0:\n",
    "                temp=gains.argmax()\n",
    "                lastscores[temp]=scores[temp]\n",
    "                self.neighbours[temp].append(elt)\n",
    "\n",
    "        indice=0\n",
    "        for elt in self.neighbours:\n",
    "            clf=linear_model.LinearRegression(fit_intercept=False, normalize=True, copy_X=True, n_jobs=-1) \n",
    "            clf.fit(train[elt], y)\n",
    "            self.clfs.append(clf)\n",
    "            if self.verbose:\n",
    "                print(indice, lastscores[indice], elt)\n",
    "            indice=indice+1\n",
    "                    \n",
    "    def transform(self, train):\n",
    "        indice=0\n",
    "        for elt in self.neighbours:\n",
    "            #this line generates a warning. Could be avoided by working and returning\n",
    "            #with a copy of train.\n",
    "            #kept this way for memory management\n",
    "            train['neighbour'+str(indice)]=self.clfs[indice].predict(train[elt])\n",
    "            indice=indice+1\n",
    "        return train\n",
    "    \n",
    "    def fit_transform(self, train, y):\n",
    "        self.fit(train, y)\n",
    "        return self.transform(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a home-made class attempt to remove outliers by successive quantization on residuals\n",
    "class recurrent_linear_approx():\n",
    "    def __init__(self, quant=.999, limit_size_train=.9):\n",
    "        self.quant=quant\n",
    "        self.limit_size_train=limit_size_train\n",
    "        self.bestmodel=[]\n",
    "       \n",
    "    def fit(self, train, y):\n",
    "        internal_model=linear_model.RidgeCV(fit_intercept=False)\n",
    "        bestscore=1e15\n",
    "        better=True\n",
    "        indextrain=train.dropna().index\n",
    "        limitlen=len(train)*self.limit_size_train\n",
    "        while better:\n",
    "            internal_model.fit(train.ix[indextrain], y.ix[indextrain])\n",
    "            score=metrics.mean_squared_error(internal_model.predict(train.ix[indextrain]), y.ix[indextrain])\n",
    "            if score < bestscore:\n",
    "                bestscore=score\n",
    "                self.bestmodel=internal_model\n",
    "                residual=y.ix[indextrain]-internal_model.predict(train.ix[indextrain])\n",
    "                indextrain=residual[abs(residual)<=abs(residual).quantile(self.quant)].index\n",
    "                if len(indextrain)<limitlen:\n",
    "                    better=False\n",
    "            else:\n",
    "                better=False\n",
    "                self.bestmodel=internal_model\n",
    "\n",
    "    def predict(self, test):\n",
    "        return self.bestmodel.predict(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fitting linear model on ', 'technical_22')\n",
      "('fitting linear model on ', 'technical_20')\n",
      "('fitting linear model on ', 'technical_30_d')\n",
      "('fitting linear model on ', 'technical_20_d')\n",
      "('fitting linear model on ', 'technical_30')\n",
      "('fitting linear model on ', 'technical_13')\n",
      "('fitting linear model on ', 'technical_34')\n"
     ]
    }
   ],
   "source": [
    "#generation of linear models\n",
    "cols2fit=['technical_22','technical_20', 'technical_30_d', 'technical_20_d', 'technical_30', \n",
    "'technical_13', 'technical_34']\n",
    "models=[]\n",
    "columns=[]\n",
    "residuals=[]\n",
    "for elt in cols2fit:\n",
    "    print(\"fitting linear model on \", elt)\n",
    "    model=recurrent_linear_approx(quant=.99, limit_size_train=.9)\n",
    "    model.fit(train.loc[:,[elt]],train.loc[:, 'y'])\n",
    "    models.append(model)\n",
    "    columns.append([elt])\n",
    "    residuals.append(abs(model.predict(train[[elt]].fillna(d_mean))-train.y))\n",
    "\n",
    "train=train.fillna(d_mean)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding new features\n",
      "(0, 0.00037784202140755951, [u'fundamental_63', u'fundamental_20'])\n",
      "(1, 0.00037783532752655447, [u'technical_33', u'fundamental_42'])\n",
      "(2, 0.00037783311563543975, [u'fundamental_29', u'fundamental_23'])\n",
      "(3, 0.00037783940206281841, [u'fundamental_41', u'fundamental_46'])\n",
      "(4, 0.0003778421669267118, [u'technical_41', u'fundamental_44'])\n",
      "(5, 0.00037783652078360319, [u'fundamental_7', u'fundamental_0'])\n",
      "(6, 0.00037780959974043071, [u'fundamental_54', u'fundamental_5'])\n",
      "(7, 0.00037784167216159403, [u'fundamental_17', 'nbnulls'])\n",
      "(8, 0.00037783363950438797, [u'technical_6', u'fundamental_45'])\n",
      "(9, 0.00037784193409606814, [u'fundamental_6', u'fundamental_19'])\n",
      "(10, 0.00037783838342875242, [u'technical_0', u'fundamental_35'])\n",
      "(11, 0.00037783297011628747, [u'fundamental_31', u'technical_44'])\n",
      "(12, 0.00037781347054988146, [u'fundamental_12', u'fundamental_13'])\n",
      "(13, 0.00037781929131597281, [u'fundamental_18', u'fundamental_26'])\n",
      "(14, 0.00037784263258799911, [u'fundamental_22', u'fundamental_49'])\n",
      "(15, 0.00037783448351547122, ['technical_13_na', u'fundamental_52'])\n",
      "(16, 0.00037784251617267728, [u'fundamental_61', u'technical_1'])\n",
      "(17, 0.00037781518767587841, [u'technical_17', u'fundamental_43'])\n",
      "(18, 0.00037783494917675853, [u'technical_24', 'technical_44_na'])\n",
      "(19, 0.00037784254527650774, [u'technical_14', u'fundamental_58'])\n",
      "(20, 0.000377667136490345, [u'technical_12', u'technical_20'])\n",
      "(21, 0.00037783668613258385, ['technical_34_d', u'fundamental_28'])\n",
      "(22, 0.00037784242886118591, [u'technical_5', u'fundamental_10'])\n",
      "(23, 0.00037774000783854698, ['technical_30_d', u'technical_22'])\n",
      "(24, 0.00037782650906592607, [u'fundamental_55', u'technical_16'])\n",
      "(25, 0.00037781510036438704, [u'derived_2', u'fundamental_59'])\n",
      "(26, 0.00037783753941766918, [u'fundamental_40', u'derived_0'])\n",
      "(27, 0.00037783489096909761, [u'technical_32', u'technical_38'])\n",
      "(28, 0.00037780459388159215, [u'fundamental_36', 'technical_9_na'])\n",
      "(29, 0.00037783264997415245, [u'fundamental_47', u'fundamental_50'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training trees\n",
      "                        0\n",
      "fundamental_23   0.007772\n",
      "neighbour13      0.007933\n",
      "technical_0_na   0.008082\n",
      "technical_21     0.008340\n",
      "technical_40     0.008478\n",
      "neighbour19      0.009486\n",
      "fundamental_53   0.009672\n",
      "fundamental_18   0.010207\n",
      "technical_9_na   0.010329\n",
      "technical_38_na  0.011448\n",
      "technical_19     0.011714\n",
      "fundamental_8    0.012363\n",
      "technical_32_na  0.012939\n",
      "fundamental_58   0.013495\n",
      "technical_7      0.013629\n",
      "technical_17     0.014164\n",
      "technical_30_d   0.014676\n",
      "neighbour23      0.016480\n",
      "technical_44_na  0.023595\n",
      "technical_6      0.024417\n",
      "neighbour28      0.026658\n",
      "technical_20_d   0.027523\n",
      "technical_2      0.033885\n",
      "neighbour8       0.037184\n",
      "technical_43     0.041851\n",
      "neighbour20      0.052079\n",
      "fundamental_11   0.067610\n",
      "technical_11     0.073563\n",
      "technical_20     0.092986\n",
      "technical_30     0.121845\n"
     ]
    }
   ],
   "source": [
    "#adding all trees generated by a tree regressor\n",
    "print(\"adding new features\")\n",
    "featureexpander=createLinearFeatures(n_neighbours=30, max_elts=2, verbose=True, random_state=rnd)\n",
    "index2use=train[abs(train.y)<0.086].index\n",
    "featureexpander.fit(train.ix[index2use,cols],train.ix[index2use,'y'])\n",
    "trainer=featureexpander.transform(train[cols])\n",
    "treecols=trainer.columns\n",
    "\n",
    "print(\"training trees\")\n",
    "model = ensemble.ExtraTreesRegressor(n_estimators=100, max_depth=4, n_jobs=-1, random_state=rnd, verbose=0)\n",
    "model.fit(trainer,train.y)\n",
    "print(pd.DataFrame(model.feature_importances_,index=treecols).sort_values(by=[0]).tail(30))\n",
    "for elt in model.estimators_:\n",
    "    models.append(elt)\n",
    "    columns.append(treecols)\n",
    "    residuals.append(abs(elt.predict(trainer)-train.y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting best models:\n",
      "0     177555\n",
      "1     119791\n",
      "18     75122\n",
      "2      65190\n",
      "6      45465\n",
      "3      27463\n",
      "15     21027\n",
      "41     18533\n",
      "37     18134\n",
      "52     15273\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#model selection : create a new target selecting models with lowest asolute residual for each line\n",
    "#the objective at this step is to keep only the few best elements which should\n",
    "#lead to a better generalization\n",
    "num_to_keep=10\n",
    "targetselector=np.array(residuals).T\n",
    "targetselector=np.argmin(targetselector, axis=1)\n",
    "print(\"selecting best models:\")\n",
    "print(pd.Series(targetselector).value_counts().head(num_to_keep))\n",
    "\n",
    "tokeep=pd.Series(targetselector).value_counts().head(num_to_keep).index\n",
    "tokeepmodels=[]\n",
    "tokeepcolumns=[]\n",
    "tokeepresiduals=[]\n",
    "for elt in tokeep:\n",
    "    tokeepmodels.append(models[elt])\n",
    "    tokeepcolumns.append(columns[elt])\n",
    "    tokeepresiduals.append(residuals[elt])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training selection model\n",
      "                        0\n",
      "technical_6      0.008497\n",
      "fundamental_21   0.008564\n",
      "technical_11     0.009069\n",
      "technical_16_na  0.009074\n",
      "technical_27     0.009353\n",
      "technical_9_na   0.010328\n",
      "technical_35     0.010585\n",
      "technical_20_d   0.011106\n",
      "technical_30_d   0.011864\n",
      "technical_13     0.012851\n",
      "neighbour28      0.013220\n",
      "technical_2      0.013555\n",
      "technical_36     0.015371\n",
      "technical_17     0.015576\n",
      "technical_43     0.015749\n",
      "technical_29     0.017248\n",
      "technical_0_na   0.017879\n",
      "technical_32_na  0.019099\n",
      "neighbour23      0.020424\n",
      "technical_38_na  0.021112\n",
      "technical_30     0.021985\n",
      "neighbour20      0.024403\n",
      "technical_14     0.031557\n",
      "technical_7      0.031869\n",
      "technical_40     0.038140\n",
      "technical_20     0.044078\n",
      "technical_34     0.077328\n",
      "neighbour18      0.102321\n",
      "technical_44_na  0.115022\n",
      "technical_22     0.131173\n",
      "end of trainind, now predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6, 0.022921731779680134, -0.1275476969156128)\n",
      "(200, 19, -0.16869656636732488, -0.11998823422526599)\n",
      "(300, 28, -0.050756281559958698, -0.11969185541748409)\n",
      "(400, 36, -0.14310864159303302, -0.12002827888008366)\n",
      "(500, 44, -0.12920172381612383, -0.12107404327716705)\n",
      "(600, 55, -0.13926399577265822, -0.11999842810919668)\n",
      "(700, 64, -0.23252552884455999, -0.12707330697343383)\n",
      "(800, 73, -0.080823434599645819, -0.12987168531543578)\n",
      "(900, 80, -0.14540602738078329, -0.12976604214373177)\n",
      "0.0191473798751\n"
     ]
    }
   ],
   "source": [
    "#creating a new target for a model in charge of predicting which model is best for the current line\n",
    "targetselector=np.array(tokeepresiduals).T\n",
    "targetselector=np.argmin(targetselector, axis=1)\n",
    "\n",
    "print(\"training selection model\")\n",
    "modelselector = ensemble.ExtraTreesClassifier(n_estimators=100, max_depth=4, n_jobs=-1, random_state=rnd, verbose=0)\n",
    "modelselector.fit(trainer, targetselector)\n",
    "print(pd.DataFrame(modelselector.feature_importances_,index=treecols).sort_values(by=[0]).tail(30))\n",
    "\n",
    "# original: lastvalues=train[train.timestamp==905][['id']+diff_cols].copy()\n",
    "lastvalues=train[train.timestamp==train.timestamp.iloc[-1]][['id']+diff_cols].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"end of trainind, now predicting\")\n",
    "indice=0\n",
    "countplus=0\n",
    "rewards=[]\n",
    "while True:\n",
    "    indice+=1\n",
    "    test = o.features\n",
    "    test[\"nbnulls\"]=test.isnull().sum(axis=1)\n",
    "    if add_nas_ft:\n",
    "        for elt in nas_cols:\n",
    "            test[elt + '_na'] = pd.isnull(test[elt]).apply(lambda x: 1 if x else 0)\n",
    "    test=test.fillna(d_mean)\n",
    "    d_mean=test.median(axis=0)\n",
    "\n",
    "    pred = o.target\n",
    "    if add_diff_ft:\n",
    "        #creating deltas from lastvalues\n",
    "        indexcommun=list(set(lastvalues.id) & set(test.id))\n",
    "        lastvalues=pd.concat([test[test.id.isin(indexcommun)]['id'],\n",
    "            pd.DataFrame(test[diff_cols][test.id.isin(indexcommun)].values-lastvalues[diff_cols][lastvalues.id.isin(indexcommun)].values,\n",
    "            columns=diff_cols, index=test[test.id.isin(indexcommun)].index)],\n",
    "            axis=1)\n",
    "        #adding them to test data    \n",
    "        test=test.merge(right=lastvalues, how='left', on='id', suffixes=('','_d')).fillna(0)\n",
    "        #storing new lastvalues\n",
    "        lastvalues=test[['id']+diff_cols].copy()\n",
    "    \n",
    "    testid=test.id\n",
    "    test=featureexpander.transform(test[cols])\n",
    "    #prediction using modelselector and models list\n",
    "    selected_prediction = modelselector.predict_proba(test.loc[: ,treecols])\n",
    "    for ind,elt in enumerate(tokeepmodels):\n",
    "        pred['y']+=selected_prediction[:,ind]*elt.predict(test[tokeepcolumns[ind]])\n",
    "\n",
    "    indexbase=pred.index\n",
    "    pred.index=testid    \n",
    "    oldpred=pred['y']\n",
    "    pred.index=indexbase\n",
    "    \n",
    "    o, reward, done, info = env.step(pred)\n",
    "    rewards.append(reward)\n",
    "    if reward>0:\n",
    "        countplus+=1\n",
    "    \n",
    "    if indice%100==0:\n",
    "        print(indice, countplus, reward, np.mean(rewards))\n",
    "        \n",
    "    if done:\n",
    "        print(info[\"public_score\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targetselector2=np.array(residuals).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp=(np.mean(targetselector2,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 18, 2, 6, 3, 15, 41, 37, 52], dtype='int64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 22, 86, 72, 33, 97, 85, 57, 84, 12])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.argsort()[:(num_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting best models:\n",
      "0      177555\n",
      "1      119791\n",
      "18      75122\n",
      "2       65190\n",
      "6       45465\n",
      "3       27463\n",
      "15      21027\n",
      "41      18533\n",
      "37      18134\n",
      "52      15273\n",
      "104     12419\n",
      "22      11741\n",
      "63      11710\n",
      "64      11572\n",
      "17      10208\n",
      "97       8289\n",
      "102      8281\n",
      "23       8001\n",
      "84       6467\n",
      "44       6434\n",
      "29       6124\n",
      "12       6115\n",
      "30       5435\n",
      "95       5205\n",
      "99       4916\n",
      "48       4663\n",
      "87       4578\n",
      "67       4576\n",
      "68       4229\n",
      "106      4110\n",
      "        ...  \n",
      "49        574\n",
      "72        568\n",
      "77        566\n",
      "83        566\n",
      "25        550\n",
      "92        542\n",
      "60        532\n",
      "56        523\n",
      "61        509\n",
      "27        499\n",
      "7         461\n",
      "4         432\n",
      "78        373\n",
      "35        353\n",
      "21        338\n",
      "100       324\n",
      "28        300\n",
      "59        266\n",
      "76        240\n",
      "82        191\n",
      "90        187\n",
      "45        180\n",
      "75        176\n",
      "31        144\n",
      "74        143\n",
      "43        138\n",
      "71        128\n",
      "42        124\n",
      "9         110\n",
      "91         65\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "targetselector=np.array(residuals).T\n",
    "targetselector=np.argmin(targetselector, axis=1)\n",
    "print(\"selecting best models:\")\n",
    "print(pd.Series(targetselector).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ExtraTreesClassifier.predict_proba of ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=17,\n",
       "           verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelselector.predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(805548, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(tokeepresiduals).T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(805548,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetselector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
