{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806298, 111)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'rolling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-30328313a5c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;31m#a quick way to obtain deltas from one month to another but it is false on the first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m#month of each id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_d\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;31m#removing month 0 to reduce the impact of erroneous deltas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jiguo\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2358\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[1;32m-> 2360\u001b[1;33m                                  (type(self).__name__, name))\n\u001b[0m\u001b[0;32m   2361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'rolling'"
     ]
    }
   ],
   "source": [
    "import kagglegym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import ensemble, linear_model, metrics\n",
    "\n",
    "env = kagglegym.make()\n",
    "o = env.reset()\n",
    "train = o.train\n",
    "print(train.shape)\n",
    "d_mean= train.median(axis=0)\n",
    "train[\"nbnulls\"]=train.isnull().sum(axis=1)\n",
    "col=[x for x in train.columns if x not in ['id', 'timestamp', 'y']]\n",
    "\n",
    "rnd=17\n",
    "\n",
    "#keeping na information on some columns (best selected by the tree algorithms)\n",
    "add_nas_ft=True\n",
    "nas_cols=['technical_9', 'technical_0', 'technical_32', 'technical_16', 'technical_38', \n",
    "'technical_44', 'technical_20', 'technical_30', 'technical_13']\n",
    "#columns kept for evolution from one month to another (best selected by the tree algorithms)\n",
    "add_diff_ft=True\n",
    "diff_cols=['technical_22','technical_20', 'technical_30', 'technical_13', 'technical_34']\n",
    "\n",
    "#homemade class used to infer randomly on the way the model learns\n",
    "class createLinearFeatures:\n",
    "    \n",
    "    def __init__(self, n_neighbours=1, max_elts=None, verbose=True, random_state=None):\n",
    "        self.rnd=random_state\n",
    "        self.n=n_neighbours\n",
    "        self.max_elts=max_elts\n",
    "        self.verbose=verbose\n",
    "        self.neighbours=[]\n",
    "        self.clfs=[]\n",
    "        \n",
    "    def fit(self,train,y):\n",
    "        if self.rnd!=None:\n",
    "            random.seed(self.rnd)\n",
    "        if self.max_elts==None:\n",
    "            self.max_elts=len(train.columns)\n",
    "        list_vars=list(train.columns)\n",
    "        random.shuffle(list_vars)\n",
    "        \n",
    "        lastscores=np.zeros(self.n)+1e15\n",
    "\n",
    "        for elt in list_vars[:self.n]:\n",
    "            self.neighbours.append([elt])\n",
    "        list_vars=list_vars[self.n:]\n",
    "        \n",
    "        for elt in list_vars:\n",
    "            indice=0\n",
    "            scores=[]\n",
    "            for elt2 in self.neighbours:\n",
    "                if len(elt2)<self.max_elts:\n",
    "                    clf=linear_model.LinearRegression(fit_intercept=False, normalize=True, copy_X=True, n_jobs=-1) \n",
    "                    clf.fit(train[elt2+[elt]], y)\n",
    "                    scores.append(metrics.mean_squared_error(y,clf.predict(train[elt2 + [elt]])))\n",
    "                    indice=indice+1\n",
    "                else:\n",
    "                    scores.append(lastscores[indice])\n",
    "                    indice=indice+1\n",
    "            gains=lastscores-scores\n",
    "            if gains.max()>0:\n",
    "                temp=gains.argmax()\n",
    "                lastscores[temp]=scores[temp]\n",
    "                self.neighbours[temp].append(elt)\n",
    "\n",
    "        indice=0\n",
    "        for elt in self.neighbours:\n",
    "            clf=linear_model.LinearRegression(fit_intercept=False, normalize=True, copy_X=True, n_jobs=-1) \n",
    "            clf.fit(train[elt], y)\n",
    "            self.clfs.append(clf)\n",
    "            if self.verbose:\n",
    "                print(indice, lastscores[indice], elt)\n",
    "            indice=indice+1\n",
    "                    \n",
    "    def transform(self, train):\n",
    "        indice=0\n",
    "        trainer=train#.drop(train.columns, 1) ####\n",
    "        for elt in self.neighbours:\n",
    "            #this line generates a warning. Could be avoided by working and returning\n",
    "            #with a copy of train.\n",
    "            #kept this way for memory management\n",
    "            trainer['neighbour'+str(indice)]=self.clfs[indice].predict(train[elt]) ####\n",
    "            indice=indice+1\n",
    "        return trainer ####\n",
    "    \n",
    "    def fit_transform(self, train, y):\n",
    "        self.fit(train, y)\n",
    "        return self.transform(train)\n",
    "\n",
    "#a home-made class attempt to remove outliers by successive quantization on residuals\n",
    "class recurrent_linear_approx():\n",
    "    def __init__(self, quant=.999, limit_size_train=.9):\n",
    "        self.quant=quant\n",
    "        self.limit_size_train=limit_size_train\n",
    "        self.bestmodel=[]\n",
    "       \n",
    "    def fit(self, train, y):\n",
    "        internal_model=linear_model.RidgeCV(fit_intercept=False)\n",
    "        bestscore=1e15\n",
    "        better=True\n",
    "        indextrain=train.dropna().index\n",
    "        limitlen=len(train)*self.limit_size_train\n",
    "        while better:\n",
    "            internal_model.fit(train.ix[indextrain], y.ix[indextrain])\n",
    "            score=metrics.mean_squared_error(internal_model.predict(train.ix[indextrain]), y.ix[indextrain])\n",
    "            if score < bestscore:\n",
    "                bestscore=score\n",
    "                self.bestmodel=internal_model\n",
    "                residual=y.ix[indextrain]-internal_model.predict(train.ix[indextrain])\n",
    "                indextrain=residual[abs(residual)<=abs(residual).quantile(self.quant)].index\n",
    "                if len(indextrain)<limitlen:\n",
    "                    better=False\n",
    "            else:\n",
    "                better=False\n",
    "                self.bestmodel=internal_model\n",
    "\n",
    "    def predict(self, test):\n",
    "        return self.bestmodel.predict(test)\n",
    "\n",
    "if add_nas_ft:\n",
    "    for elt in nas_cols:\n",
    "        train[elt + '_na'] = pd.isnull(train[elt]).apply(lambda x: 1 if x else 0)\n",
    "        #no need to keep columns with no information\n",
    "        if len(train[elt + '_na'].unique())==1:\n",
    "            print(\"removed:\", elt, '_na')\n",
    "            del train[elt + '_na']\n",
    "            nas_cols.remove(elt)\n",
    "\n",
    "\n",
    "if add_diff_ft:\n",
    "    train=train.sort_values(by=['id','timestamp'])\n",
    "    for elt in diff_cols:\n",
    "        #a quick way to obtain deltas from one month to another but it is false on the first\n",
    "        #month of each id\n",
    "        train[elt+\"_d\"]= train[elt].rolling(2).apply(lambda x:x[1]-x[0]).fillna(0)\n",
    "    #removing month 0 to reduce the impact of erroneous deltas\n",
    "    train=train[train.timestamp!=0]\n",
    "\n",
    "print(train.shape)\n",
    "cols=[x for x in train.columns if x not in ['id', 'timestamp', 'y']]\n",
    "\n",
    "\n",
    "#generation of linear models\n",
    "cols2fit=['technical_22','technical_20', 'technical_30_d', 'technical_20_d', 'technical_30', \n",
    "'technical_13', 'technical_34']\n",
    "models=[]\n",
    "columns=[]\n",
    "residuals=[]\n",
    "predicts=[]\n",
    "for elt in cols2fit:\n",
    "    print(\"fitting linear model on \", elt)\n",
    "    model=recurrent_linear_approx(quant=.99, limit_size_train=.9)\n",
    "    model.fit(train.loc[:,[elt]],train.loc[:, 'y'])\n",
    "    models.append(model)\n",
    "    columns.append([elt])\n",
    "    residuals.append(model.predict(train[[elt]].fillna(d_mean))-train.y) ####\n",
    "    predicts.append(model.predict(train[[elt]].fillna(d_mean)))####\n",
    "\n",
    "train=train.fillna(d_mean)\n",
    "    \n",
    "#adding all trees generated by a tree regressor\n",
    "print(\"adding new features\")\n",
    "featureexpander=createLinearFeatures(n_neighbours=30, max_elts=2, verbose=True, random_state=rnd)\n",
    "index2use=train[abs(train.y)<0.086].index\n",
    "featureexpander.fit(train.ix[index2use,cols],train.ix[index2use,'y'])\n",
    "trainer=featureexpander.transform(train[cols])\n",
    "treecols=trainer.columns\n",
    "#treecols=train.columns.append(trainer.columns)####\n",
    "\n",
    "print(\"training trees\")\n",
    "model = ensemble.ExtraTreesRegressor(n_estimators=100, max_depth=4, n_jobs=-1, random_state=rnd, verbose=0)\n",
    "model.fit(trainer,train.y)\n",
    "#print(pd.DataFrame(model.feature_importances_,index=treecols).sort_values(by=[0]).tail(30))\n",
    "for elt in model.estimators_:\n",
    "    models.append(elt)\n",
    "    columns.append(treecols)\n",
    "    residuals.append(elt.predict(trainer)-train.y)####\n",
    "    predicts.append(elt.predict(trainer))####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training selection model\n",
      "end of trainind, now predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5, -0.014618958442202191, -0.12914553087787722)\n",
      "(200, 12, -0.1811864623213045, -0.12546221949538147)\n",
      "(300, 21, -0.048618446176743602, -0.12485855470658788)\n",
      "(400, 28, -0.13810289507814758, -0.12438785995211715)\n",
      "(500, 37, -0.12617694869483767, -0.12469270498517503)\n",
      "(600, 46, -0.1581481152725483, -0.12338637062458811)\n",
      "(700, 59, -0.24436982508700497, -0.12956524903634209)\n",
      "(800, 67, -0.077390690584910091, -0.13247442991999553)\n",
      "(900, 74, -0.1734548630592139, -0.1328314461258201)\n",
      "0.010171833353\n"
     ]
    }
   ],
   "source": [
    "#model selection : create a new target selecting models with lowest asolute residual for each line\n",
    "#the objective at this step is to keep only the few best elements which should\n",
    "#lead to a better generalization\n",
    "num_to_keep=10\n",
    "targetselector=np.array(residuals).T\n",
    "#targetselector=np.argmin(targetselector, axis=1)\n",
    "targetselector=(np.mean(abs(targetselector),axis=0)) ####\n",
    "#print(\"selecting best models:\")\n",
    "#print(pd.Series(targetselector).value_counts().head(num_to_keep))\n",
    "\n",
    "#tokeep=pd.Series(targetselector).value_counts().head(num_to_keep).index\n",
    "tokeep=targetselector.argsort()[:(num_to_keep)] ####\n",
    "tokeepmodels=[]\n",
    "tokeepcolumns=[]\n",
    "tokeepresiduals=[]\n",
    "tokeeppredicts=[] ####\n",
    "for elt in tokeep:\n",
    "    tokeepmodels.append(models[elt])\n",
    "    tokeepcolumns.append(columns[elt])\n",
    "    tokeepresiduals.append(residuals[elt])\n",
    "    tokeeppredicts.append(predicts[elt]) ####\n",
    "    trainer['prediction'+str(elt)]=predicts[elt] ########\n",
    "\n",
    "#creating a new target for a model in charge of predicting which model is best for the current line\n",
    "#targetselector=np.array(tokeeppredicts).T ####\n",
    "#targetselector=np.argmin(targetselector, axis=1) ####\n",
    "\n",
    "print(\"training selection model\")\n",
    "#modelselector = ensemble.ExtraTreesClassifier(n_estimators=100, max_depth=4, n_jobs=-1, random_state=rnd, verbose=0)\n",
    "#modelselector.fit(trainer, targetselector)\n",
    "# modelselector = xgb.XGBRegressor(objective='reg:linear', colsample_bytree=.8, \\\n",
    "#                         subsample=.9, min_child_weight=1000, base_score=.5) ####\n",
    "modelselector=ensemble.ExtraTreesRegressor(n_estimators=100, max_depth=4, n_jobs=-1, random_state=rnd, verbose=0) ####\n",
    "modelselector.fit(trainer,train.y) ####\n",
    "#print(pd.DataFrame(modelselector.feature_importances_,index=treecols).sort_values(by=[0]).tail(30))\n",
    "\n",
    "#lastvalues=train[train.timestamp==905][['id']+diff_cols].copy()\n",
    "lastvalues=train[train.timestamp==train.timestamp.iloc[-1]][['id']+diff_cols].copy()####\n",
    "\n",
    "print(\"end of trainind, now predicting\")\n",
    "indice=0\n",
    "countplus=0\n",
    "rewards=[]\n",
    "while True:\n",
    "    indice+=1\n",
    "    test = o.features\n",
    "    test[\"nbnulls\"]=test.isnull().sum(axis=1)\n",
    "    if add_nas_ft:\n",
    "        for elt in nas_cols:\n",
    "            test[elt + '_na'] = pd.isnull(test[elt]).apply(lambda x: 1 if x else 0)\n",
    "    test=test.fillna(d_mean)\n",
    "    d_mean=test.median(axis=0)####\n",
    "\n",
    "    pred = o.target\n",
    "    if add_diff_ft:\n",
    "        #creating deltas from lastvalues\n",
    "        indexcommun=list(set(lastvalues.id) & set(test.id))\n",
    "        lastvalues=pd.concat([test[test.id.isin(indexcommun)]['id'],\n",
    "            pd.DataFrame(test[diff_cols][test.id.isin(indexcommun)].values-lastvalues[diff_cols][lastvalues.id.isin(indexcommun)].values,\n",
    "            columns=diff_cols, index=test[test.id.isin(indexcommun)].index)],\n",
    "            axis=1)\n",
    "        #adding them to test data    \n",
    "        test=test.merge(right=lastvalues, how='left', on='id', suffixes=('','_d')).fillna(0)\n",
    "        #storing new lastvalues\n",
    "        lastvalues=test[['id']+diff_cols].copy()\n",
    "    \n",
    "    testid=test.id\n",
    "    test=featureexpander.transform(test[cols])\n",
    "    #prediction using modelselector and models list\n",
    "    #selected_prediction = modelselector.predict_proba(test.loc[: ,treecols])\n",
    "    #y_test=np.zeros((test.shape[0], len(tokeep))) ####\n",
    "    for ind,elt in enumerate(tokeepmodels):\n",
    "        #pred['y']+=selected_prediction[:,ind]*elt.predict(test[tokeepcolumns[ind]])\n",
    "        #y_test[:, ind]=elt.predict(test[tokeepcolumns[ind]]) ####\n",
    "        test['prediction'+str(elt)]=elt.predict(test[tokeepcolumns[ind]]) ########\n",
    "        \n",
    "    #pred['y']=modelselector.predict(y_test) ####\n",
    "    pred['y']=modelselector.predict(test) ########\n",
    "\n",
    "    indexbase=pred.index\n",
    "    pred.index=testid    \n",
    "    oldpred=pred['y']\n",
    "    pred.index=indexbase\n",
    "    \n",
    "    o, reward, done, info = env.step(pred)\n",
    "    rewards.append(reward)\n",
    "    if reward>0:\n",
    "        countplus+=1\n",
    "    \n",
    "    if indice%100==0:\n",
    "        print(indice, countplus, reward, np.mean(rewards))\n",
    "        \n",
    "    if done:\n",
    "        print(info[\"public_score\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
